{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526f2415",
   "metadata": {},
   "source": [
    "### Task 1: Polynomial Regression - Model Comparison\n",
    "**Objective**: Compare Linear Regression vs Polynomial Regression and understand when to use each\n",
    "\n",
    "**Dataset**: `Task-Datasets/task1_polynomial_data.csv`\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the dataset containing Experience_Years and Salary data (15 rows)\n",
    "2. Visualize the data with a scatter plot\n",
    "3. Build and train the following models:\n",
    "   - Linear Regression\n",
    "   - Polynomial Regression with degree=2\n",
    "   - Polynomial Regression with degree=3\n",
    "   - Polynomial Regression with degree=4\n",
    "4. Create visualizations for each model showing:\n",
    "   - Original data points\n",
    "   - Regression line/curve\n",
    "   - Proper title and labels\n",
    "5. Make a prediction: What salary would you expect for someone with 8.5 years of experience using each model?\n",
    "6. Compare the predictions and explain which model seems most appropriate and why\n",
    "\n",
    "**Deliverable**: \n",
    "- Code with all four models\n",
    "- Four separate visualizations\n",
    "- Prediction comparison\n",
    "- Brief written explanation (markdown cell) of which model is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57250d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd9b6ae6",
   "metadata": {},
   "source": [
    "### Task 2: Support Vector Regression (SVR)\n",
    "**Objective**: Implement SVR and understand the importance of feature scaling\n",
    "\n",
    "**Dataset**: `Task-Datasets/task2_svr_data.csv`\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the dataset with Temperature and Ice_Cream_Sales (20 rows)\n",
    "2. **Without feature scaling**:\n",
    "   - Build and train a Linear Regression model\n",
    "   - Visualize the results\n",
    "3. **Without feature scaling**:\n",
    "   - Build and train an SVR model with RBF kernel\n",
    "   - Visualize the results\n",
    "   - Note what happens to the predictions\n",
    "4. **With proper feature scaling**:\n",
    "   - Apply StandardScaler to both X and y\n",
    "   - Build and train an SVR model with RBF kernel\n",
    "   - Visualize the results (remember to inverse transform for visualization)\n",
    "5. Make a prediction: What ice cream sales would you expect at 27Â°C?\n",
    "   - Use both Linear Regression and properly scaled SVR\n",
    "   - Compare the predictions\n",
    "6. Explain why feature scaling is critical for SVR\n",
    "\n",
    "**Deliverable**: \n",
    "- Code showing SVR with and without scaling\n",
    "- Comparison with Linear Regression\n",
    "- Visualizations\n",
    "- Explanation of why scaling matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0ece5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7a86de9",
   "metadata": {},
   "source": [
    "### Task 3: Decision Tree Regression\n",
    "**Objective**: Implement Decision Tree Regression and visualize decision boundaries\n",
    "\n",
    "**Dataset**: `Task-Datasets/task3_decision_tree_data.csv`\n",
    "\n",
    "**Instructions**:\n",
    "1. Load the dataset with Hours_Studied and Exam_Score (25 rows)\n",
    "2. Build and train a Decision Tree Regressor (use random_state=0)\n",
    "3. Create two visualizations:\n",
    "   - **Standard resolution**: Plot original data and predictions\n",
    "   - **High resolution**: Use np.arange with step 0.1 to show the step-like nature of decision trees\n",
    "4. Compare with Linear Regression:\n",
    "   - Build a Linear Regression model on the same data\n",
    "   - Visualize both models on the same plot or separate plots\n",
    "5. Make predictions:\n",
    "   - Predict exam score for 23 hours of study\n",
    "   - Compare Decision Tree vs Linear Regression predictions\n",
    "6. Explain the advantage of Decision Tree for this type of data\n",
    "\n",
    "**Deliverable**: \n",
    "- Decision Tree model with high-resolution visualization\n",
    "- Comparison with Linear Regression\n",
    "- Predictions\n",
    "- Explanation of when Decision Trees are advantageous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28f489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1656e223",
   "metadata": {},
   "source": [
    "## Part 2: Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf79a4bf",
   "metadata": {},
   "source": [
    "### Assignment 1: Comprehensive Model Comparison\n",
    "**Objective**: Build and compare all three regression techniques on the same dataset\n",
    "\n",
    "**Scenario**: A company wants to predict salaries based on position levels. The salary structure follows an exponential growth pattern as employees move up the hierarchy.\n",
    "\n",
    "**Dataset**: `Assignment-Dataset/assignment1_salary_prediction.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary for details**\n",
    "- 10 position levels with corresponding salaries\n",
    "- Non-linear relationship (exponential growth)\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "#### 1. Data Exploration\n",
    "- Load and examine the dataset\n",
    "- Create a scatter plot to visualize the relationship\n",
    "- Describe the pattern you observe\n",
    "\n",
    "#### 2. Model 1: Linear Regression\n",
    "- Build and train a Linear Regression model\n",
    "- Visualize predictions\n",
    "- Predict salary for position level 6.5\n",
    "\n",
    "#### 3. Model 2: Polynomial Regression\n",
    "- Test multiple polynomial degrees (2, 3, 4, 5, 6)\n",
    "- For each degree:\n",
    "  - Train the model\n",
    "  - Visualize the fit\n",
    "  - Predict salary for position level 6.5\n",
    "- Compare results and identify the best degree\n",
    "\n",
    "#### 4. Model 3: Support Vector Regression\n",
    "- Apply proper feature scaling (StandardScaler)\n",
    "- Build SVR with RBF kernel\n",
    "- Visualize results (inverse transform for display)\n",
    "- Predict salary for position level 6.5\n",
    "\n",
    "#### 5. Model 4: Decision Tree Regression\n",
    "- Build Decision Tree Regressor\n",
    "- Create high-resolution visualization\n",
    "- Predict salary for position level 6.5\n",
    "\n",
    "#### 6. Model Comparison\n",
    "- Create a comparison table with:\n",
    "  - Model name\n",
    "  - Prediction for level 6.5\n",
    "  - Visual assessment (does it fit the data well?)\n",
    "  - Pros and cons for this dataset\n",
    "- Create a combined visualization showing all models\n",
    "\n",
    "#### 7. Analysis and Recommendations\n",
    "- Which model performs best for this salary prediction problem?\n",
    "- Why does it perform better than others?\n",
    "- What are the risks of each approach?\n",
    "- Which model would you recommend for production use?\n",
    "\n",
    "**Deliverable**:\n",
    "- Complete implementation of all four models\n",
    "- Individual visualizations for each model\n",
    "- Combined comparison visualization\n",
    "- Comparison table\n",
    "- Comprehensive analysis report (markdown cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed521701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d4e0b8",
   "metadata": {},
   "source": [
    "### Assignment 2: Multi-Feature Regression\n",
    "**Objective**: Apply advanced regression techniques to multi-feature datasets\n",
    "\n",
    "**Scenario**: A building management company wants to predict energy consumption based on environmental factors to optimize HVAC systems and reduce costs.\n",
    "\n",
    "**Dataset**: `Assignment-Dataset/assignment2_energy_efficiency.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary for details**\n",
    "- 100 records with 4 features\n",
    "- Features: Temperature, Humidity, Wind_Speed, Solar_Radiation\n",
    "- Target: Energy_Consumption\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "#### 1. Data Preparation\n",
    "- Load and explore the dataset\n",
    "- Display statistical summary\n",
    "- Check for missing values\n",
    "- Split data: 80% training, 20% testing (random_state=42)\n",
    "\n",
    "#### 2. Baseline: Multiple Linear Regression\n",
    "- Build Multiple Linear Regression model\n",
    "- Train on training set\n",
    "- Make predictions on test set\n",
    "- Calculate metrics:\n",
    "  - RÂ² score\n",
    "  - Mean Absolute Error (MAE)\n",
    "  - Root Mean Squared Error (RMSE)\n",
    "\n",
    "#### 3. Model 2: Support Vector Regression\n",
    "- Apply StandardScaler to features\n",
    "- Build SVR with RBF kernel\n",
    "- Train and predict\n",
    "- Calculate same metrics\n",
    "- Compare with baseline\n",
    "\n",
    "#### 4. Model 3: Decision Tree Regression\n",
    "- Build Decision Tree Regressor\n",
    "- Try different max_depth values (3, 5, 10, None)\n",
    "- For each depth:\n",
    "  - Train and predict\n",
    "  - Calculate metrics\n",
    "- Identify best max_depth\n",
    "\n",
    "#### 5. Model Evaluation and Comparison\n",
    "- Create comparison table with all metrics\n",
    "- Visualize predictions vs actual values for each model:\n",
    "  - Scatter plot (predicted vs actual)\n",
    "  - Add diagonal line (perfect prediction)\n",
    "- Create residual plots for each model\n",
    "\n",
    "#### 6. Feature Importance Analysis (Decision Tree only)\n",
    "- Extract feature importances from best Decision Tree\n",
    "- Create bar plot showing importance of each feature\n",
    "- Interpret which environmental factors most affect energy consumption\n",
    "\n",
    "#### 7. Business Insights\n",
    "- Which model is most accurate for energy prediction?\n",
    "- Which environmental factor has the biggest impact?\n",
    "- Provide 3 recommendations for optimizing energy consumption\n",
    "- Discuss trade-offs between model accuracy and interpretability\n",
    "\n",
    "**Deliverable**:\n",
    "- Complete preprocessing and model implementation\n",
    "- Three trained models with performance metrics\n",
    "- Comparison visualizations\n",
    "- Feature importance analysis\n",
    "- Business insights report (markdown cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d9b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80ff1beb",
   "metadata": {},
   "source": [
    "### Assignment 3: Time Series Prediction with Polynomial Features\n",
    "**Objective**: Apply regression techniques to time-series data with feature engineering\n",
    "\n",
    "**Scenario**: A financial analyst wants to predict stock closing prices based on daily trading data to inform investment decisions.\n",
    "\n",
    "**Dataset**: `Assignment-Dataset/assignment3_stock_prices.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary for details**\n",
    "- 90 days of trading data\n",
    "- Features: Day, Opening_Price, High_Price, Low_Price, Volume\n",
    "- Target: Closing_Price\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "#### 1. Data Exploration\n",
    "- Load and examine the dataset\n",
    "- Create time series plot showing opening and closing prices over time\n",
    "- Calculate and display correlation matrix\n",
    "- Identify which features are most correlated with closing price\n",
    "\n",
    "#### 2. Feature Engineering\n",
    "- Create new features:\n",
    "  - `Price_Range` = High_Price - Low_Price\n",
    "  - `Price_Change` = Closing_Price - Opening_Price (shift by 1 to avoid data leakage)\n",
    "  - `Volume_MA` = Moving average of volume (window=5)\n",
    "- Handle any NaN values from moving average\n",
    "- Select final feature set for modeling\n",
    "\n",
    "#### 3. Data Preparation\n",
    "- Split data: Use first 70 days for training, last 20 days for testing (time series split)\n",
    "- **Important**: Do not shuffle the data (maintain temporal order)\n",
    "\n",
    "#### 4. Model 1: Multiple Linear Regression\n",
    "- Build baseline model with original features\n",
    "- Train and predict\n",
    "- Calculate RÂ², MAE, RMSE\n",
    "\n",
    "#### 5. Model 2: Polynomial Regression\n",
    "- Create polynomial features (degree=2) for numeric features\n",
    "- Build and train model\n",
    "- Make predictions\n",
    "- Calculate metrics\n",
    "- Compare with baseline\n",
    "\n",
    "#### 6. Model 3: Decision Tree Regression\n",
    "- Build Decision Tree with best max_depth (test values: 3, 5, 7, 10)\n",
    "- Train and predict\n",
    "- Calculate metrics\n",
    "- Analyze feature importance\n",
    "\n",
    "#### 7. Visualization and Analysis\n",
    "- Create time series plot comparing:\n",
    "  - Actual closing prices\n",
    "  - Predictions from each model\n",
    "  - Use different colors/styles for each\n",
    "- Create comparison table with all metrics\n",
    "- Plot residuals over time for each model\n",
    "\n",
    "#### 8. Model Selection and Limitations\n",
    "- Which model performs best on the test set?\n",
    "- Discuss overfitting concerns\n",
    "- What are the limitations of using regression for stock price prediction?\n",
    "- What additional data or features might improve predictions?\n",
    "- Would you recommend using these models for actual trading? Why or why not?\n",
    "\n",
    "**Deliverable**:\n",
    "- Feature engineering code\n",
    "- Three regression models with proper time series handling\n",
    "- Comprehensive visualizations\n",
    "- Performance comparison table\n",
    "- Critical analysis of limitations (markdown cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecbbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d051f0",
   "metadata": {},
   "source": [
    "## Part 3: Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b6581",
   "metadata": {},
   "source": [
    "### Real-World Project: Car Price Prediction System\n",
    "\n",
    "**Objective**: Apply all learned concepts from Weeks 14-15 in a comprehensive machine learning project\n",
    "\n",
    "**Scenario**: You are a data scientist at an automotive company that buys and sells used cars. The company wants to develop an intelligent pricing system that accurately predicts car prices based on various features to:\n",
    "- Price vehicles competitively\n",
    "- Identify undervalued cars for purchase\n",
    "- Maximize profit margins\n",
    "- Provide instant price estimates to customers\n",
    "\n",
    "**Dataset**: `Assessment-Dataset/assessment_car_price_prediction.csv`\n",
    "\n",
    "**Dataset Description**:\n",
    "- **Check Data Dictionary for complete details**\n",
    "- 200 records of used cars\n",
    "- Mix of numerical and categorical features\n",
    "- Features include: Brand, Year, Mileage, Engine_Size, Horsepower, Fuel_Type, Transmission, Previous_Owners, Accident_History, Service_Records\n",
    "- Target: Price (in dollars)\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 1: Data Understanding & Preprocessing (Week 14 Skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147a267",
   "metadata": {},
   "source": [
    "#### 1.1 Data Loading and Exploration\n",
    "- Load the dataset and display basic information:\n",
    "  - Shape (rows, columns)\n",
    "  - Data types\n",
    "  - First and last 5 rows\n",
    "- Statistical summary for numerical features\n",
    "- Check for missing values\n",
    "- Identify categorical vs numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d7677e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6ead8ca",
   "metadata": {},
   "source": [
    "#### 1.2 Exploratory Data Analysis (EDA)\n",
    "- Create visualizations:\n",
    "  - Distribution of target variable (Price) - histogram\n",
    "  - Price distribution by Brand - box plot\n",
    "  - Price distribution by Fuel_Type - box plot\n",
    "  - Correlation heatmap for numerical features\n",
    "  - Scatter plot: Mileage vs Price\n",
    "  - Scatter plot: Year vs Price\n",
    "- Identify key insights from visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c71332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e064df40",
   "metadata": {},
   "source": [
    "#### 1.3 Data Preprocessing\n",
    "\n",
    "**A. Handle Categorical Variables:**\n",
    "- Encode categorical features:\n",
    "  - Brand (OneHotEncoder)\n",
    "  - Fuel_Type (OneHotEncoder)\n",
    "  - Transmission (OneHotEncoder or LabelEncoder)\n",
    "  - Accident_History (LabelEncoder: Yes=1, No=0)\n",
    "  - Service_Records (LabelEncoder: Yes=1, No=0)\n",
    "- Handle dummy variable trap (drop first column for OneHotEncoded features)\n",
    "\n",
    "**B. Train-Test Split:**\n",
    "- Split data: 70% training, 30% testing\n",
    "- Use random_state=42 for reproducibility\n",
    "\n",
    "**C. Feature Scaling:**\n",
    "- Identify which numerical features need scaling\n",
    "- Apply StandardScaler to numerical features\n",
    "- Fit on training data, transform both training and test sets\n",
    "\n",
    "**D. Validation:**\n",
    "- Print shapes of X_train, X_test, y_train, y_test\n",
    "- Verify no missing values remain\n",
    "- Display first 5 rows of preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7acdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02a1e4dc",
   "metadata": {},
   "source": [
    "### Phase 2: Model Development (Week 15 Skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8f6ff",
   "metadata": {},
   "source": [
    "#### 2.1 Baseline Model: Multiple Linear Regression\n",
    "- Build Multiple Linear Regression model\n",
    "- Train on training set\n",
    "- Make predictions on both training and test sets\n",
    "- Calculate evaluation metrics:\n",
    "  - RÂ² score (train and test)\n",
    "  - Mean Absolute Error (MAE)\n",
    "  - Mean Squared Error (MSE)\n",
    "  - Root Mean Squared Error (RMSE)\n",
    "- Store results for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3a146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c163afc6",
   "metadata": {},
   "source": [
    "#### 2.2 Model 2: Polynomial Regression\n",
    "- Create polynomial features (test degrees: 2, 3)\n",
    "- For each degree:\n",
    "  - Transform features\n",
    "  - Train model\n",
    "  - Calculate all metrics\n",
    "  - Check for overfitting (compare train vs test RÂ²)\n",
    "- Select best polynomial degree\n",
    "- **Note**: Be careful with high degrees - may cause overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de299323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b737a647",
   "metadata": {},
   "source": [
    "#### 2.3 Model 3: Support Vector Regression\n",
    "- Ensure features are properly scaled\n",
    "- Build SVR with RBF kernel\n",
    "- Try different parameters:\n",
    "  - kernel='rbf', C=100, gamma='auto'\n",
    "  - kernel='rbf', C=1000, gamma='scale'\n",
    "- Train and evaluate each configuration\n",
    "- Select best SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471c226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62023dbe",
   "metadata": {},
   "source": [
    "#### 2.4 Model 4: Decision Tree Regression\n",
    "- Build Decision Tree Regressor\n",
    "- Test different hyperparameters:\n",
    "  - max_depth: 3, 5, 10, None\n",
    "  - min_samples_split: 2, 5, 10\n",
    "  - min_samples_leaf: 1, 2, 5\n",
    "- For each configuration:\n",
    "  - Train model\n",
    "  - Calculate metrics\n",
    "  - Check for overfitting\n",
    "- Select best Decision Tree model\n",
    "- Extract and visualize feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f948ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c5b4c68",
   "metadata": {},
   "source": [
    "### Phase 3: Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f7625",
   "metadata": {},
   "source": [
    "#### 3.1 Comprehensive Model Comparison\n",
    "- Create comparison table with all models:\n",
    "\n",
    "| Model | Train RÂ² | Test RÂ² | MAE | RMSE | Training Time |\n",
    "|-------|----------|---------|-----|------|---------------|\n",
    "| Multiple Linear Regression | ... | ... | ... | ... | ... |\n",
    "| Polynomial Regression (degree X) | ... | ... | ... | ... | ... |\n",
    "| SVR (best params) | ... | ... | ... | ... | ... |\n",
    "| Decision Tree (best params) | ... | ... | ... | ... | ... |\n",
    "\n",
    "- Analyze which model performs best\n",
    "- Identify any overfitting issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da876b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8af80a17",
   "metadata": {},
   "source": [
    "#### 3.2 Visualization - Predicted vs Actual\n",
    "For each model, create:\n",
    "- Scatter plot: Predicted vs Actual prices (test set)\n",
    "- Add diagonal line representing perfect predictions\n",
    "- Color points by prediction error magnitude\n",
    "- Add RÂ² score to plot title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e37b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1ac8c6",
   "metadata": {},
   "source": [
    "#### 3.3 Residual Analysis\n",
    "For each model:\n",
    "- Calculate residuals (actual - predicted)\n",
    "- Create residual plot (residuals vs predicted values)\n",
    "- Plot histogram of residuals\n",
    "- Analyze residual patterns:\n",
    "  - Are residuals randomly distributed?\n",
    "  - Is there any pattern indicating model limitations?\n",
    "  - Are there outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef4fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebe5b95a",
   "metadata": {},
   "source": [
    "#### 3.4 Feature Importance Analysis\n",
    "- For Decision Tree model:\n",
    "  - Extract feature importances\n",
    "  - Create horizontal bar plot\n",
    "  - List top 10 most important features\n",
    "- Interpret results:\n",
    "  - Which features most influence car prices?\n",
    "  - Are the results intuitive?\n",
    "  - Any surprising findings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4adbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c1013a",
   "metadata": {},
   "source": [
    "### Phase 4: Model Selection & Business Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342e025",
   "metadata": {},
   "source": [
    "#### 4.1 Final Model Selection\n",
    "Based on your analysis, select the best model and justify your choice considering:\n",
    "- Accuracy (Test RÂ², RMSE)\n",
    "- Overfitting concerns\n",
    "- Interpretability\n",
    "- Training/prediction speed\n",
    "- Business requirements\n",
    "\n",
    "Write a comprehensive justification (at least 200 words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17693621",
   "metadata": {},
   "source": [
    "*Your justification here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c78808",
   "metadata": {},
   "source": [
    "#### 4.2 Price Predictions for New Cars\n",
    "Create 3 hypothetical cars with different characteristics:\n",
    "\n",
    "**Car 1**: Budget sedan\n",
    "- Brand: Toyota, Year: 2015, Mileage: 80000, Engine_Size: 1.5, Horsepower: 110\n",
    "- Fuel_Type: Petrol, Transmission: Manual, Previous_Owners: 2\n",
    "- Accident_History: No, Service_Records: Yes\n",
    "\n",
    "**Car 2**: Luxury sedan\n",
    "- Brand: BMW, Year: 2020, Mileage: 30000, Engine_Size: 3.0, Horsepower: 320\n",
    "- Fuel_Type: Diesel, Transmission: Automatic, Previous_Owners: 1\n",
    "- Accident_History: No, Service_Records: Yes\n",
    "\n",
    "**Car 3**: Older vehicle with issues\n",
    "- Brand: Ford, Year: 2012, Mileage: 150000, Engine_Size: 2.0, Horsepower: 150\n",
    "- Fuel_Type: Petrol, Transmission: Manual, Previous_Owners: 4\n",
    "- Accident_History: Yes, Service_Records: No\n",
    "\n",
    "For each car:\n",
    "- Preprocess the data correctly\n",
    "- Make prediction using your best model\n",
    "- Explain the predicted price\n",
    "- Discuss confidence in the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34644a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "466c8000",
   "metadata": {},
   "source": [
    "#### 4.3 Business Insights & Recommendations\n",
    "\n",
    "Provide comprehensive analysis addressing:\n",
    "\n",
    "**A. Key Findings:**\n",
    "- What are the top 5 factors affecting car prices?\n",
    "- Which car brands retain value best?\n",
    "- How much does mileage affect price?\n",
    "- Impact of accident history on pricing\n",
    "\n",
    "**B. Business Recommendations:**\n",
    "1. Inventory Management:\n",
    "   - Which types of cars should the company prioritize buying?\n",
    "   - Which features add most value?\n",
    "\n",
    "2. Pricing Strategy:\n",
    "   - How can the company identify underpriced cars in the market?\n",
    "   - What price adjustments would maximize profit?\n",
    "\n",
    "3. Customer Advisory:\n",
    "   - What should customers know about factors affecting car value?\n",
    "   - How can sellers maximize their car's value?\n",
    "\n",
    "**C. Model Limitations:**\n",
    "- What are the limitations of your chosen model?\n",
    "- When might the model's predictions be unreliable?\n",
    "- What additional data would improve predictions?\n",
    "\n",
    "**D. Future Improvements:**\n",
    "- How could the model be enhanced?\n",
    "- What other machine learning techniques might work better?\n",
    "- How should the model be maintained and updated?\n",
    "\n",
    "Write at least 500 words addressing these points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373f00e",
   "metadata": {},
   "source": [
    "*Your comprehensive business analysis here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82839b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Challenges\n",
    "\n",
    "If you want to go beyond the requirements:\n",
    "\n",
    "### Bonus 1: Ensemble Methods\n",
    "- Implement Random Forest Regressor\n",
    "- Compare with Decision Tree\n",
    "- Does ensemble improve performance?\n",
    "\n",
    "### Bonus 2: Hyperparameter Tuning\n",
    "- Use GridSearchCV or RandomizedSearchCV\n",
    "- Optimize SVR or Decision Tree hyperparameters\n",
    "- Document improvement achieved\n",
    "\n",
    "### Bonus 3: Cross-Validation\n",
    "- Implement k-fold cross-validation (k=5)\n",
    "- Calculate average scores across folds\n",
    "- Compare with simple train-test split\n",
    "\n",
    "### Bonus 4: Outlier Detection and Handling\n",
    "- Identify outliers in price data\n",
    "- Test model performance with and without outliers\n",
    "- Recommend outlier handling strategy\n",
    "\n",
    "### Bonus 5: Model Deployment Preparation\n",
    "- Save your best model using joblib or pickle\n",
    "- Create a function that takes raw car data and returns price prediction\n",
    "- Write a simple CLI or function interface for predictions\n",
    "\n",
    "### Bonus 6: Additional Regression Techniques\n",
    "- Try Ridge Regression or Lasso Regression\n",
    "- Implement Gradient Boosting Regressor\n",
    "- Compare with your previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f6b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0f62364",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Guidelines\n",
    "\n",
    "### Deliverables:\n",
    "1. **This Jupyter Notebook** with:\n",
    "   - All code cells executed and showing outputs\n",
    "   - Clear markdown explanations for each section\n",
    "   - Well-commented code\n",
    "   - All visualizations displayed\n",
    "\n",
    "2. **Code Quality Requirements**:\n",
    "   - Use meaningful variable names\n",
    "   - Add comments for complex operations\n",
    "   - Follow consistent code style\n",
    "   - Remove any debugging/test code\n",
    "\n",
    "3. **Documentation Requirements (Report)**:\n",
    "   - Executive summary at the beginning\n",
    "   - Methodology explanation\n",
    "   - Clear interpretation of results\n",
    "   - Conclusions and recommendations\n",
    "\n",
    "\n",
    "## Link to your publication\n",
    "\n",
    "*Add your publication link here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aeb7a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee02c191",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Good luck with your assignments! Remember, the goal is not just to build models, but to understand when and why to use each regression technique, and how to apply them to solve real-world business problems.**\n",
    "\n",
    "**Key Takeaways from Week 15:**\n",
    "- Polynomial Regression: Best for non-linear relationships with smooth curves\n",
    "- SVR: Powerful for non-linear patterns, requires feature scaling\n",
    "- Decision Trees: Excellent for capturing complex, non-continuous patterns\n",
    "- Model selection depends on data characteristics and business requirements\n",
    "- Always validate on test data to check for overfitting\n",
    "\n",
    "## Happy New Year 2026! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fef2c8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
